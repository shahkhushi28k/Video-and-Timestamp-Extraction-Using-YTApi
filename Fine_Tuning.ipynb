{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1XH-nTUdzBN",
        "outputId": "891b5077-e027-41e6-d45d-0c84011d875e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.137.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
            "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8yljPTjoMK4",
        "outputId": "78276e54-e8ee-482f-d6c2-88c3116fb27b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans)\n",
            "  Downloading hstspreload-2024.9.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2024.9.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15718 sha256=3fdca0919bd295ce6ee95e4865d59e2e0eaf1374fbf428450b84448b4490c35e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/81/ea/8b030407f8ebfc2f857814e086bb22ca2d4fea1a7be63652ab\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.8\n",
            "    Uninstalling idna-3.8:\n",
            "      Successfully uninstalled idna-3.8\n",
            "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.9.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yrgawrbidr1J"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "from youtube_transcript_api import YouTubeTranscriptApi as yta, NoTranscriptFound"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API key\n",
        "API_KEY = 'AIzaSyCzAl1InDV_CrXNLYP4JPqQyNGqjOyJT_Q'\n",
        "youtube = build('youtube', 'v3', developerKey=API_KEY)"
      ],
      "metadata": {
        "id": "A6r0Ssevdzo2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_youtube(query, max_results=10):\n",
        "    \"\"\"Search YouTube for videos matching the query.\"\"\"\n",
        "    try:\n",
        "        request = youtube.search().list(\n",
        "            q=query,\n",
        "            part='id,snippet',\n",
        "            maxResults=max_results\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        videos = []\n",
        "        for item in response['items']:\n",
        "            video_id = item['id'].get('videoId')\n",
        "            title = item['snippet']['title']\n",
        "            description = item['snippet']['description']\n",
        "            if video_id:\n",
        "                videos.append({\n",
        "                    'video_id': video_id,\n",
        "                    'title': title,\n",
        "                    'description': description\n",
        "                })\n",
        "        return videos\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching YouTube: {e}\")\n",
        "        return []\n",
        "\n",
        "def analyze_transcript(transcript, query):\n",
        "    \"\"\"Analyze the transcript to find time lapses where the query appears.\"\"\"\n",
        "    time_lapses = []\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    for entry in transcript:\n",
        "        text = entry['text']\n",
        "        start_time = entry['start']\n",
        "        if query_lower in text.lower():\n",
        "            time_lapses.append({\n",
        "                'time': start_time,\n",
        "                'text': text\n",
        "            })\n",
        "\n",
        "    return time_lapses\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Convert seconds to a formatted time string.\"\"\"\n",
        "    minutes, seconds = divmod(seconds, 60)\n",
        "    hours, minutes = divmod(minutes, 60)\n",
        "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
        "\n",
        "def get_transcript(video_id):\n",
        "    \"\"\"Retrieve the transcript for a given video ID.\"\"\"\n",
        "    languages_to_try = ['en']\n",
        "    for lang in languages_to_try:\n",
        "        try:\n",
        "            transcript = yta.get_transcript(video_id, languages=[lang])\n",
        "            return transcript\n",
        "        except NoTranscriptFound:\n",
        "            print(f\"No transcript found for video {video_id} in {lang}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting transcript for video {video_id}: {e}\")\n",
        "            break\n",
        "    return None\n",
        "\n",
        "def display_results(user_query, max_results=10):\n",
        "    \"\"\"Display search results with time lapses and text for the query.\"\"\"\n",
        "    videos = search_youtube(user_query, max_results)\n",
        "\n",
        "    results = []\n",
        "    for video in videos:\n",
        "        transcript = get_transcript(video['video_id'])\n",
        "        if transcript:\n",
        "            time_lapses = analyze_transcript(transcript, user_query)\n",
        "            results.append({\n",
        "                'title': video['title'],\n",
        "                'link': f\"https://www.youtube.com/watch?v={video['video_id']}\",\n",
        "                'description': video['description'],\n",
        "                'time_lapses': [\n",
        "                    {\n",
        "                        'time': format_time(t['time']),\n",
        "                        'text': t['text']\n",
        "                    } for t in time_lapses\n",
        "                ]\n",
        "            })\n",
        "        else:\n",
        "            print(f\"No transcript available for video {video['video_id']}\")\n",
        "\n",
        "    # Sort results by the number of time lapses in descending order\n",
        "    results.sort(key=lambda x: len(x['time_lapses']), reverse=True)\n",
        "\n",
        "    # Print results\n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"{i + 1}. {result['title']}\")\n",
        "        print(f\"   Link: {result['link']}\")\n",
        "        print(f\"   Description: {result['description']}\")\n",
        "        if result['time_lapses']:\n",
        "            print(f\"   Time Lapse          Text\")\n",
        "            for time_lapse in result['time_lapses']:\n",
        "                print(f\"   {time_lapse['time']}            {time_lapse['text']}\")\n",
        "        else:\n",
        "            print(\"   No relevant time lapses found.\")\n",
        "        print(\"---------\")\n"
      ],
      "metadata": {
        "id": "TIOXDhCGk299"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "display_results(\"fine tuning\", max_results=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWvbCqNgebhd",
        "outputId": "ef9b9500-149f-4c89-998e-8950a8b1fba4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Fine-tuning Large Language Models (LLMs) | w/ Example Code\n",
            "   Link: https://www.youtube.com/watch?v=eC6Hd1hFvos\n",
            "   Description: CXOs, VPs, & Directors... I offer custom AI workshops: https://www.shawhintalebi.com/ai-workshops This is the 5th video in a ...\n",
            "   Time Lapse          Text\n",
            "   00:00:33            what is model fine tuning the way I like\n",
            "   00:01:06            the edges fine tuning is taking this raw\n",
            "   00:03:19            to learn more about model fine tuning\n",
            "   00:03:21            and how open AI did their fine tuning\n",
            "   00:04:14            fine tuning you don't have to rely on\n",
            "   00:05:00            differentiate fine tuning with\n",
            "   00:07:14            was supervised fine tuning so\n",
            "   00:09:01            approach to model fine tuning here I\n",
            "   00:09:06            first choose your fine tuning task so\n",
            "   00:09:55            number four the fine tuning the model\n",
            "   00:18:27            examples for model fine tuning the next\n",
            "   00:26:56            that we evaluated before 5 fine tuning\n",
            "---------\n",
            "2. Fine Tune Qwen2 VL Model using Llama Factory\n",
            "   Link: https://www.youtube.com/watch?v=5IqkZ_yms4k\n",
            "   Description: In this video, I walk you through the step-by-step process of fine-tuning the Qwen2-VL model using LlamaFactory. You'll learn how ...\n",
            "   Time Lapse          Text\n",
            "   00:09:40            training jobs or fine tuning whatever\n",
            "   00:12:53            now uh fine tuning method Laura is fine\n",
            "   00:12:56            if you want to do full fine tuning you\n",
            "   00:13:59            want to use supervised fine tuning you\n",
            "   00:15:41            it will start fine tuning it okay now\n",
            "   00:20:07            SF supervised fine tuning we have do\n",
            "   00:20:23            sets the template the fine tuning and\n",
            "   00:21:13            fine tuning has now started you can see\n",
            "   00:21:16            the fine tuning now you can fine tune on\n",
            "   00:21:20            this fine tuning is started and I'm\n",
            "   00:22:03            one more way of fine tuning it guys that\n",
            "---------\n",
            "3. Fine-tuning a Neural Network explained\n",
            "   Link: https://www.youtube.com/watch?v=5T-iXNNiwIs\n",
            "   Description: In this video, we explain the concept of fine-tuning an artificial neural network. Fine-tuning is also known as “transfer learning.\n",
            "   Time Lapse          Text\n",
            "   00:00:17            networks fine tuning is very closely\n",
            "   00:00:36            trucks fine tuning is a way of applying\n",
            "   00:00:40            specifically fine tuning is a process\n",
            "   00:04:23            implementation of fine tuning written\n",
            "---------\n",
            "4. The Fine-Tuning of the Universe\n",
            "   Link: https://www.youtube.com/watch?v=EE76nwimuT0\n",
            "   Description: For more resources visit: http://www.reasonablefaith.org/finetuning View the Kalam Cosmological Argument animation video: ...\n",
            "   No relevant time lapses found.\n",
            "---------\n",
            "5. The Fine Tuning Argument (Arguments For God Episode #6)\n",
            "   Link: https://www.youtube.com/watch?v=VeERxx2wftY\n",
            "   Description: MERCHANDISE NOW AVAILABLE* Even Christopher Hitchens was periodically stumped by this favourite among apologists.\n",
            "   No relevant time lapses found.\n",
            "---------\n",
            "6. Sean Carroll - Why Fine-tuning Seems Designed\n",
            "   Link: https://www.youtube.com/watch?v=gvrORNrLH_M\n",
            "   Description: Watch all Closer To Truth interviews with Sean Carroll here: https://shorturl.at/qS047 If all is random and our universe is the only ...\n",
            "   No relevant time lapses found.\n",
            "---------\n",
            "7. Why is our universe fine-tuned for life? | Brian Greene\n",
            "   Link: https://www.youtube.com/watch?v=bf7BXwVeyWw\n",
            "   Description: http://www.ted.com At the heart of modern cosmology is a mystery: Why does our universe appear so exquisitely tuned to create ...\n",
            "   No relevant time lapses found.\n",
            "---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xt6OgT5kqDOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}